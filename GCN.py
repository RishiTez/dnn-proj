# -*- coding: utf-8 -*-
"""GNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tfp56fE9ZTNct_KC8C-NPUqs192md_OJ
"""

!pip install torch_geometric
!pip install optuna

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt

from torch.nn import Linear
from torch_geometric.utils import to_networkx
from torch_geometric.nn import GCNConv

df = pd.read_csv("/content/weatherHistory.csv")
df

df_numeric = df.select_dtypes(include='number')
df = df_numeric
df

df.isnull().sum()

df.duplicated().sum()

df = df.drop_duplicates()
df

print("Number of features:", df.shape[1])

from sklearn.preprocessing import StandardScaler

# Select features excluding target and non-numerical columns
features = ['Temperature (C)', 'Humidity', 'Wind Speed (km/h)',
            'Wind Bearing (degrees)', 'Visibility (km)',
            'Loud Cover', 'Pressure (millibars)']

# Normalize features
scaler = StandardScaler()
df[features] = scaler.fit_transform(df[features])

from sklearn.neighbors import NearestNeighbors
from torch_geometric.data import Data
import torch

x = torch.tensor(df[features].values, dtype=torch.float)
y = torch.tensor(df['Apparent Temperature (C)'].values, dtype=torch.float)

k = 5
knn = NearestNeighbors(n_neighbors=k+1)
knn.fit(x)
distances, indices = knn.kneighbors(x, return_distance=True)

edge_index = []
edge_weight = []

for i in range(len(indices)):
    for idx, j in enumerate(indices[i][1:]):
        edge_index.append([i, j])
        weight = 1 / (distances[i][idx + 1] + 1e-5)
        edge_weight.append(weight)

edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
edge_weight = torch.tensor(edge_weight, dtype=torch.float)

edge_index_rev = edge_index.flip(0)
edge_weight_rev = edge_weight

edge_index = torch.cat([edge_index, edge_index_rev], dim=1)
edge_weight = torch.cat([edge_weight, edge_weight_rev], dim=0)

data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)

print(data)

print(f"Number of nodes: {data.num_nodes}")
print(f"Number of edges: {data.num_edges}")
print(f"Number of features: {data.num_features}")

import networkx as nx
import matplotlib.pyplot as plt
from torch_geometric.utils import to_networkx

G = to_networkx(data, to_undirected=True)

max_nodes = 100
max_edges = 500

if len(G.nodes) > max_nodes:
    sampled_nodes = list(G.nodes)[:max_nodes]
    G = G.subgraph(sampled_nodes)

if len(G.edges) > max_edges:
    sampled_edges = list(G.edges)[:max_edges]
    G = G.edge_subgraph(sampled_edges)

plt.figure(figsize=(10, 8))
nx.draw_kamada_kawai(G, with_labels=True, node_size=50, font_size=8, node_color='lightgreen', font_weight='bold')
plt.show()

class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(data.num_features, 7)
        self.conv2 = GCNConv(7, 1)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        edge_attr = data.edge_attr

        x = self.conv1(x, edge_index, edge_attr)
        x = torch.relu(x)
        x = self.conv2(x, edge_index, edge_attr)

        return x

model = GCN()
print(model)

import torch.optim as optim
from torch_geometric.loader import DataLoader
import torch.nn as nn

# DataLoader for training (batch size set to 1)
train_loader = DataLoader([data], batch_size=1, shuffle=True)

# Model, optimizer, and loss function
model = GCN()
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = nn.MSELoss()

best_loss = float('inf')
patience = 20
counter = 0

for epoch in range(500):
    model.train()
    optimizer.zero_grad()
    for batch in train_loader:
        out = model(batch)
        loss = criterion(out, batch.y.view(-1, 1))
        loss.backward()
        optimizer.step()

    if loss.item() < best_loss - 0.01:
        best_loss = loss.item()
        counter = 0
    else:
        counter += 1

    if counter >= patience:
        print(f"Early stopping at epoch {epoch+1}. Final loss: {best_loss:.4f}")
        break

    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

model.eval()
with torch.no_grad():
    predictions = model(data).squeeze()  # shape: [num_nodes]
    true_values = data.y

from sklearn.metrics import mean_squared_error, r2_score
import torch

mse = mean_squared_error(true_values.cpu(), predictions.cpu())
rmse = mse ** 0.5
r2 = r2_score(true_values.cpu(), predictions.cpu())

print(f"RMSE: {rmse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.scatter(true_values.cpu(), predictions.cpu(), alpha=0.5, s=10)
plt.plot([true_values.min(), true_values.max()],
         [true_values.min(), true_values.max()], 'r--')
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title("GCN: True vs Predicted Node Targets")
plt.grid(True)
plt.show()
