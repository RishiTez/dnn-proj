# -*- coding: utf-8 -*-
"""Apparent Temp_Pred_RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15D_2FfxmdqF9XcPOA3wJVga7vOtHuWwD
"""

import pandas as pd
df = pd.read_csv('/content/weatherHistory.csv')

df

df.describe()

df_numeric = df.select_dtypes(include='number')
corr_matrix = df_numeric.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

df.isnull().sum()

df[df['Precip Type'].isnull()].head()

df.dropna()

df.duplicated().sum()

df = df.drop_duplicates(
)

import matplotlib.pyplot as plt

# visualize data
plt.figure(figsize=(10, 6))
plt.scatter(df['Temperature (C)'], df['Apparent Temperature (C)'], alpha=0.5)
plt.title('Temperature vs Apparent Temperature')
plt.xlabel('Temperature (C)')
plt.ylabel('Apparent Temperature (C)')
plt.show()

# Handling Outliers
df_original = df.copy()
columns_with_outliers = ['Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Pressure (millibars)']

Q1 = df[columns_with_outliers].quantile(0.25)
Q3 = df[columns_with_outliers].quantile(0.75)
IQR = Q3 - Q1

# Define bounds
lower_bound = Q1 - 1.0 * IQR
upper_bound = Q3 + 1.0 * IQR
outlier_mask = False
for col in columns_with_outliers:
    col_mask = (df[col] < lower_bound[col]) | (df[col] > upper_bound[col])
    outlier_mask = outlier_mask | col_mask

# Get the outlier rows
outliers = df[outlier_mask]
print(f"Number of rows with outliers: {len(outliers)}")

# cap the outliers
for col in columns_with_outliers:
    df[col] = df[col].clip(lower=lower_bound[col], upper=upper_bound[col])

"""Removing outliers for better model training"""

# Visualize the diffference
plt.figure(figsize=(15, 6))

# Before outlier treatment
plt.subplot(1, 2, 1)
plt.scatter(df_original['Temperature (C)'], df_original['Apparent Temperature (C)'], alpha=0.5)
plt.title('Before Outlier Treatment')
plt.xlabel('Temperature (C)')
plt.ylabel('Apparent Temperature (C)')

# After outlier treatment
plt.subplot(1, 2, 2)
plt.scatter(df['Temperature (C)'], df['Apparent Temperature (C)'], alpha=0.5)
plt.title('After Outlier Treatment')
plt.xlabel('Temperature (C)')
plt.ylabel('Apparent Temperature (C)')

plt.tight_layout()
plt.show()

"""Train-Test Split"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Data Preparation
df = df.select_dtypes(include='number')

X = df.drop(['Apparent Temperature (C)'], axis='columns')
y = df[['Apparent Temperature (C)']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

scaler = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

y_train_reshaped = y_train_scaled.reshape((y_train_scaled.shape[0], 1))
y_test_reshaped = y_test_scaled.reshape((y_test_scaled.shape[0], 1))

print(f'Train Shape: {X_train_reshaped.shape}, Test Shape: {X_test_reshaped.shape}')
print(f'Train Shape: {y_train_reshaped.shape}, Test Shape: {y_test_reshaped.shape}')

"""RNN model build (LSTM)"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

model = Sequential()

model.add(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
model.add(Dropout(0.2))

model.add(LSTM(64, activation='tanh', return_sequences=False))
model.add(Dropout(0.2))

model.add(Dense(1))

optimizer = Adam(learning_rate=0.0005)
model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)

model.summary()

history = model.fit(
    X_train_reshaped, y_train_reshaped,
    epochs=100,
    validation_data=(X_test_reshaped, y_test_reshaped),
    batch_size=32,
    callbacks=[early_stopping, lr_scheduler]
)

from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X_test_reshaped)

y_pred = scaler_y.inverse_transform(y_pred)
y_test_orig = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1))

mse = mean_squared_error(y_test_orig, y_pred)
r2 = r2_score(y_test_orig, y_pred)

mse, r2
